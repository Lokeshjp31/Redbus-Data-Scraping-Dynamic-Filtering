{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c66aa5da-1735-448a-ad98-fcf7760db032",
   "metadata": {},
   "source": [
    "# APSRTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b34df1c-cb44-494c-b8a3-e14f4ef84afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully into MySQL database.\n",
      "Scraping completed. Data saved to 'APSRTC_bus_details.csv' and MySQL database.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "import pymysql.cursors\n",
    "\n",
    "URL = \"https://www.redbus.in/online-booking/apsrtc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "def scrape_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(5)\n",
    "        except:\n",
    "            print(f\"No 'View Buses' button found for {url}\")\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)\n",
    "\n",
    "        bus_name_elements = driver.find_elements(By.CSS_SELECTOR, \".travels.lh-24.f-bold.d-color\")\n",
    "        bus_type_elements = driver.find_elements(By.CSS_SELECTOR, \".bus-type.f-12.m-top-16.l-color\")\n",
    "        departing_time_elements = driver.find_elements(By.CSS_SELECTOR, \".dp-time.f-19.d-color.f-bold\")\n",
    "        duration_elements = driver.find_elements(By.CSS_SELECTOR, \".dur.l-color.lh-24\")\n",
    "        reaching_time_elements = driver.find_elements(By.CSS_SELECTOR, \".bp-time.f-19.d-color.disp-Inline\")\n",
    "        star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price_elements = driver.find_elements(By.CSS_SELECTOR, \".fare.d-block\")\n",
    "        seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left')]\")\n",
    "        \n",
    "        bus_details = []\n",
    "\n",
    "        for i in range(len(bus_name_elements)):\n",
    "            try:\n",
    "                seat_availability = seat_availability_elements[i].text if i < len(seat_availability_elements) else 'N/A'\n",
    "                seat_availability = int(seat_availability) if seat_availability.isdigit() else 0\n",
    "\n",
    "                price_text = price_elements[i].text\n",
    "                price_numeric = ''.join(filter(str.isdigit, price_text))\n",
    "\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_numeric,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else 'N/A'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred while scraping bus details: {str(e)}\")\n",
    "        return bus_details\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def scrape_all_pages():\n",
    "    all_bus_details = []\n",
    "    for page in range(1, 6):\n",
    "        try:\n",
    "            driver = initialize_driver()\n",
    "            load_page(driver, URL)\n",
    "            \n",
    "            if page > 1:\n",
    "                pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                time.sleep(5)\n",
    "\n",
    "            all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "            for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                bus_details = scrape_bus_details(driver, link, name)\n",
    "                if bus_details:\n",
    "                    all_bus_details.extend(bus_details)\n",
    "            driver.quit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "\n",
    "    return all_bus_details\n",
    "\n",
    "def insert_data_into_mysql(data):\n",
    "    try:\n",
    "        connection = pymysql.connect(\n",
    "            host='127.0.0.1',\n",
    "            user='root',\n",
    "            password='Root',\n",
    "            database='redbus',\n",
    "            cursorclass=pymysql.cursors.DictCursor\n",
    "        )\n",
    "        \n",
    "        with connection:\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS APSRTC_bus_details (\n",
    "                    Route_Name TEXT,\n",
    "                    Route_Link TEXT,\n",
    "                    Bus_Name TEXT,\n",
    "                    Bus_Type TEXT,\n",
    "                    Departing_Time TIME,\n",
    "                    Duration TEXT,\n",
    "                    Reaching_Time TIME,\n",
    "                    Star_Rating FLOAT,\n",
    "                    Price DECIMAL(10,2),\n",
    "                    Seat_Availability TEXT\n",
    "                )\n",
    "                \"\"\")\n",
    "\n",
    "                for detail in data:\n",
    "                    cursor.execute(\"\"\"\n",
    "                    INSERT INTO APSRTC_bus_details (\n",
    "                        Route_Name, Route_Link, Bus_Name, Bus_Type, Departing_Time, \n",
    "                        Duration, Reaching_Time, Star_Rating, Price, Seat_Availability\n",
    "                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                    \"\"\", (\n",
    "                        detail['Route_Name'], detail['Route_Link'], detail['Bus_Name'], \n",
    "                        detail['Bus_Type'], detail['Departing_Time'], detail['Duration'], \n",
    "                        detail['Reaching_Time'], detail['Star_Rating'], detail['Price'], \n",
    "                        detail['Seat_Availability']\n",
    "                    ))\n",
    "\n",
    "            connection.commit()\n",
    "\n",
    "        print(\"Data inserted successfully into MySQL database.\")\n",
    "\n",
    "    except pymysql.MySQLError as err:\n",
    "        print(f\"Error: {err}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    all_bus_details = scrape_all_pages()\n",
    "    insert_data_into_mysql(all_bus_details)\n",
    "    df = pd.DataFrame(all_bus_details)\n",
    "    df.to_csv('APSRTC_bus_details.csv', index=False)\n",
    "    print(\"Scraping completed. Data saved to 'APSRTC_bus_details.csv' and MySQL database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c169f51-89c8-494b-b3df-a43e488669ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"C:/Users/Lokesh J/Downloads/RedBus_Scrapped_Data/APSRTC_bus_details.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7ba326-83a6-493c-b130-532129425716",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ASTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dd053ee-d4e1-4cc3-9e45-167d6c83693b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/nagaon-to-guwahati\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/goalpara-to-guwahati\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/jorhat-to-north-lakhimpur\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/jorhat-to-dibrugarh\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/north-lakhimpur-to-jorhat\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/north-lakhimpur-to-sibsagar\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/dhekiajuli-to-guwahati\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/sibsagar-to-north-lakhimpur\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/jorhat-to-dhemaji\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/dhemaji-to-jorhat\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/north-lakhimpur-to-dibrugarh\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/north-lakhimpur-to-moran\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/guwahati-to-kaliabor\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/guwahati-to-tumuki-tezpur-medical\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/dibrugarh-to-north-lakhimpur\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/moran-to-north-lakhimpur\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/biswanath-charali-to-dibrugarh\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/sibsagar-to-dhemaji\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/bihpuria-to-dibrugarh\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/haflong-to-nagaon\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/jorhat-to-gogamukh\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/dibrugarh-to-biswanath-charali\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/golaghat-to-north-lakhimpur\n",
      "Data inserted successfully into MySQL database.\n",
      "Scraping completed. Data saved to 'Assam_bus_details.csv' and MySQL database.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "import pymysql.cursors\n",
    "\n",
    "URL = \"https://www.redbus.in/online-booking/astc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "def scrape_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(5)\n",
    "        except:\n",
    "            print(f\"No 'View Buses' button found for {url}\")\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)\n",
    "\n",
    "        bus_name_elements = driver.find_elements(By.CSS_SELECTOR, \".travels.lh-24.f-bold.d-color\")\n",
    "        bus_type_elements = driver.find_elements(By.CSS_SELECTOR, \".bus-type.f-12.m-top-16.l-color\")\n",
    "        departing_time_elements = driver.find_elements(By.CSS_SELECTOR, \".dp-time.f-19.d-color.f-bold\")\n",
    "        duration_elements = driver.find_elements(By.CSS_SELECTOR, \".dur.l-color.lh-24\")\n",
    "        reaching_time_elements = driver.find_elements(By.CSS_SELECTOR, \".bp-time.f-19.d-color.disp-Inline\")\n",
    "        star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price_elements = driver.find_elements(By.CSS_SELECTOR, \".fare.d-block\")\n",
    "        seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left')]\")\n",
    "        \n",
    "        bus_details = []\n",
    "\n",
    "        for i in range(len(bus_name_elements)):\n",
    "            try:\n",
    "                seat_availability = seat_availability_elements[i].text if i < len(seat_availability_elements) else 'N/A'\n",
    "                seat_availability = int(seat_availability) if seat_availability.isdigit() else 0\n",
    "\n",
    "                price_text = price_elements[i].text\n",
    "                price_numeric = ''.join(filter(str.isdigit, price_text))\n",
    "\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_numeric,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else 'N/A'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred while scraping bus details: {str(e)}\")\n",
    "        return bus_details\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def scrape_all_pages():\n",
    "    all_bus_details = []\n",
    "    for page in range(1, 6):\n",
    "        try:\n",
    "            driver = initialize_driver()\n",
    "            load_page(driver, URL)\n",
    "            \n",
    "            if page > 1:\n",
    "                pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                time.sleep(5)\n",
    "\n",
    "            all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "            for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                bus_details = scrape_bus_details(driver, link, name)\n",
    "                if bus_details:\n",
    "                    all_bus_details.extend(bus_details)\n",
    "            driver.quit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "\n",
    "    return all_bus_details\n",
    "\n",
    "def insert_data_into_mysql(data):\n",
    "    try:\n",
    "        connection = pymysql.connect(\n",
    "            host='127.0.0.1',\n",
    "            user='root',\n",
    "            password='Root',\n",
    "            database='redbus',\n",
    "            cursorclass=pymysql.cursors.DictCursor\n",
    "        )\n",
    "        \n",
    "        with connection:\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS Assam_bus_details (\n",
    "                    Route_Name TEXT,\n",
    "                    Route_Link TEXT,\n",
    "                    Bus_Name TEXT,\n",
    "                    Bus_Type TEXT,\n",
    "                    Departing_Time TIME,\n",
    "                    Duration TEXT,\n",
    "                    Reaching_Time TIME,\n",
    "                    Star_Rating FLOAT,\n",
    "                    Price DECIMAL(10,2),\n",
    "                    Seat_Availability TEXT\n",
    "                )\n",
    "                \"\"\")\n",
    "\n",
    "                for detail in data:\n",
    "                    cursor.execute(\"\"\"\n",
    "                    INSERT INTO Assam_bus_details (\n",
    "                        Route_Name, Route_Link, Bus_Name, Bus_Type, Departing_Time, \n",
    "                        Duration, Reaching_Time, Star_Rating, Price, Seat_Availability\n",
    "                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                    \"\"\", (\n",
    "                        detail['Route_Name'], detail['Route_Link'], detail['Bus_Name'], \n",
    "                        detail['Bus_Type'], detail['Departing_Time'], detail['Duration'], \n",
    "                        detail['Reaching_Time'], detail['Star_Rating'], detail['Price'], \n",
    "                        detail['Seat_Availability']\n",
    "                    ))\n",
    "\n",
    "            connection.commit()\n",
    "\n",
    "        print(\"Data inserted successfully into MySQL database.\")\n",
    "\n",
    "    except pymysql.MySQLError as err:\n",
    "        print(f\"Error: {err}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    all_bus_details = scrape_all_pages()\n",
    "    insert_data_into_mysql(all_bus_details)\n",
    "    df = pd.DataFrame(all_bus_details)\n",
    "    df.to_csv('Assam_bus_details.csv', index=False)\n",
    "    print(\"Scraping completed. Data saved to 'Assam_bus_details.csv' and MySQL database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae4f69aa-5c5f-4c97-bcf5-1697a6b570aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"C:/Users/Lokesh J/Downloads/RedBus_Scrapped_Data/Assam_bus_details.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef984ad-75ab-412f-a520-e2d5b782d7b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Chandigarh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b7c20a1-d8c2-4cf3-a2e7-b826ca60dc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/talwara-to-chandigarh\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/chandigarh-to-dinanagar-punjab\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/dinanagar-punjab-to-chandigarh\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/hisar-haryana-to-chandigarh\n",
      "Data inserted successfully into MySQL database.\n",
      "Scraping completed. Data saved to 'Chandigarh_bus_details.csv' and MySQL database.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "import pymysql.cursors\n",
    "\n",
    "URL = \"https://www.redbus.in/online-booking/chandigarh-transport-undertaking-ctu\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "def scrape_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(5)\n",
    "        except:\n",
    "            print(f\"No 'View Buses' button found for {url}\")\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)\n",
    "\n",
    "        bus_name_elements = driver.find_elements(By.CSS_SELECTOR, \".travels.lh-24.f-bold.d-color\")\n",
    "        bus_type_elements = driver.find_elements(By.CSS_SELECTOR, \".bus-type.f-12.m-top-16.l-color\")\n",
    "        departing_time_elements = driver.find_elements(By.CSS_SELECTOR, \".dp-time.f-19.d-color.f-bold\")\n",
    "        duration_elements = driver.find_elements(By.CSS_SELECTOR, \".dur.l-color.lh-24\")\n",
    "        reaching_time_elements = driver.find_elements(By.CSS_SELECTOR, \".bp-time.f-19.d-color.disp-Inline\")\n",
    "        star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price_elements = driver.find_elements(By.CSS_SELECTOR, \".fare.d-block\")\n",
    "        seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left')]\")\n",
    "        \n",
    "        bus_details = []\n",
    "\n",
    "        for i in range(len(bus_name_elements)):\n",
    "            try:\n",
    "                seat_availability = seat_availability_elements[i].text if i < len(seat_availability_elements) else 'N/A'\n",
    "                seat_availability = int(seat_availability) if seat_availability.isdigit() else 0\n",
    "\n",
    "                price_text = price_elements[i].text\n",
    "                price_numeric = ''.join(filter(str.isdigit, price_text))\n",
    "\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_numeric,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else 'N/A'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred while scraping bus details: {str(e)}\")\n",
    "        return bus_details\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def scrape_all_pages():\n",
    "    all_bus_details = []\n",
    "    for page in range(1, 6):\n",
    "        try:\n",
    "            driver = initialize_driver()\n",
    "            load_page(driver, URL)\n",
    "            \n",
    "            if page > 1:\n",
    "                pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                time.sleep(5)\n",
    "\n",
    "            all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "            for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                bus_details = scrape_bus_details(driver, link, name)\n",
    "                if bus_details:\n",
    "                    all_bus_details.extend(bus_details)\n",
    "            driver.quit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "\n",
    "    return all_bus_details\n",
    "\n",
    "def insert_data_into_mysql(data):\n",
    "    try:\n",
    "        connection = pymysql.connect(\n",
    "            host='127.0.0.1',\n",
    "            user='root',\n",
    "            password='Root',\n",
    "            database='redbus',\n",
    "            cursorclass=pymysql.cursors.DictCursor\n",
    "        )\n",
    "        \n",
    "        with connection:\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS Chandigarh_bus_details (\n",
    "                    Route_Name TEXT,\n",
    "                    Route_Link TEXT,\n",
    "                    Bus_Name TEXT,\n",
    "                    Bus_Type TEXT,\n",
    "                    Departing_Time TIME,\n",
    "                    Duration TEXT,\n",
    "                    Reaching_Time TIME,\n",
    "                    Star_Rating FLOAT,\n",
    "                    Price DECIMAL(10,2),\n",
    "                    Seat_Availability TEXT\n",
    "                )\n",
    "                \"\"\")\n",
    "\n",
    "                for detail in data:\n",
    "                    cursor.execute(\"\"\"\n",
    "                    INSERT INTO Chandigarh_bus_details (\n",
    "                        Route_Name, Route_Link, Bus_Name, Bus_Type, Departing_Time, \n",
    "                        Duration, Reaching_Time, Star_Rating, Price, Seat_Availability\n",
    "                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                    \"\"\", (\n",
    "                        detail['Route_Name'], detail['Route_Link'], detail['Bus_Name'], \n",
    "                        detail['Bus_Type'], detail['Departing_Time'], detail['Duration'], \n",
    "                        detail['Reaching_Time'], detail['Star_Rating'], detail['Price'], \n",
    "                        detail['Seat_Availability']\n",
    "                    ))\n",
    "\n",
    "            connection.commit()\n",
    "\n",
    "        print(\"Data inserted successfully into MySQL database.\")\n",
    "\n",
    "    except pymysql.MySQLError as err:\n",
    "        print(f\"Error: {err}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    all_bus_details = scrape_all_pages()\n",
    "    insert_data_into_mysql(all_bus_details)\n",
    "    df = pd.DataFrame(all_bus_details)\n",
    "    df.to_csv('Chandigarh_bus_details.csv', index=False)\n",
    "    print(\"Scraping completed. Data saved to 'Chandigarh_bus_details.csv' and MySQL database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de2abad9-e1c9-4837-acf5-f8e88d15d9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"C:/Users/Lokesh J/Downloads/RedBus_Scrapped_Data/Chandigarh_bus_details.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ce2106-a088-4a8a-8f5c-1c076463c296",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# HSRTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d0c307c-7590-4aa3-91f3-29b130d7dcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/delhi-to-baddi-himachal-pradesh\n",
      "Data inserted successfully into MySQL database.\n",
      "Scraping completed. Data saved to 'HSRTC_bus_details.csv' and MySQL database.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "import pymysql.cursors\n",
    "\n",
    "URL = \"https://www.redbus.in/online-booking/hrtc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "def scrape_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(5)\n",
    "        except:\n",
    "            print(f\"No 'View Buses' button found for {url}\")\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)\n",
    "\n",
    "        bus_name_elements = driver.find_elements(By.CSS_SELECTOR, \".travels.lh-24.f-bold.d-color\")\n",
    "        bus_type_elements = driver.find_elements(By.CSS_SELECTOR, \".bus-type.f-12.m-top-16.l-color\")\n",
    "        departing_time_elements = driver.find_elements(By.CSS_SELECTOR, \".dp-time.f-19.d-color.f-bold\")\n",
    "        duration_elements = driver.find_elements(By.CSS_SELECTOR, \".dur.l-color.lh-24\")\n",
    "        reaching_time_elements = driver.find_elements(By.CSS_SELECTOR, \".bp-time.f-19.d-color.disp-Inline\")\n",
    "        star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price_elements = driver.find_elements(By.CSS_SELECTOR, \".fare.d-block\")\n",
    "        seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left')]\")\n",
    "        \n",
    "        bus_details = []\n",
    "\n",
    "        for i in range(len(bus_name_elements)):\n",
    "            try:\n",
    "                seat_availability = seat_availability_elements[i].text if i < len(seat_availability_elements) else 'N/A'\n",
    "                seat_availability = int(seat_availability) if seat_availability.isdigit() else 0\n",
    "\n",
    "                price_text = price_elements[i].text\n",
    "                price_numeric = ''.join(filter(str.isdigit, price_text))\n",
    "\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_numeric,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else 'N/A'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred while scraping bus details: {str(e)}\")\n",
    "        return bus_details\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def scrape_all_pages():\n",
    "    all_bus_details = []\n",
    "    for page in range(1, 5):\n",
    "        try:\n",
    "            driver = initialize_driver()\n",
    "            load_page(driver, URL)\n",
    "            \n",
    "            if page > 1:\n",
    "                pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                time.sleep(5)\n",
    "\n",
    "            all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "            for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                bus_details = scrape_bus_details(driver, link, name)\n",
    "                if bus_details:\n",
    "                    all_bus_details.extend(bus_details)\n",
    "            driver.quit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "\n",
    "    return all_bus_details\n",
    "\n",
    "def insert_data_into_mysql(data):\n",
    "    try:\n",
    "        connection = pymysql.connect(\n",
    "            host='127.0.0.1',\n",
    "            user='root',\n",
    "            password='Root',\n",
    "            database='redbus',\n",
    "            cursorclass=pymysql.cursors.DictCursor\n",
    "        )\n",
    "        \n",
    "        with connection:\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS HSRTC_bus_details (\n",
    "                    Route_Name TEXT,\n",
    "                    Route_Link TEXT,\n",
    "                    Bus_Name TEXT,\n",
    "                    Bus_Type TEXT,\n",
    "                    Departing_Time TIME,\n",
    "                    Duration TEXT,\n",
    "                    Reaching_Time TIME,\n",
    "                    Star_Rating FLOAT,\n",
    "                    Price DECIMAL(10,2),\n",
    "                    Seat_Availability TEXT\n",
    "                )\n",
    "                \"\"\")\n",
    "\n",
    "                for detail in data:\n",
    "                    cursor.execute(\"\"\"\n",
    "                    INSERT INTO HSRTC_bus_details (\n",
    "                        Route_Name, Route_Link, Bus_Name, Bus_Type, Departing_Time, \n",
    "                        Duration, Reaching_Time, Star_Rating, Price, Seat_Availability\n",
    "                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                    \"\"\", (\n",
    "                        detail['Route_Name'], detail['Route_Link'], detail['Bus_Name'], \n",
    "                        detail['Bus_Type'], detail['Departing_Time'], detail['Duration'], \n",
    "                        detail['Reaching_Time'], detail['Star_Rating'], detail['Price'], \n",
    "                        detail['Seat_Availability']\n",
    "                    ))\n",
    "\n",
    "            connection.commit()\n",
    "\n",
    "        print(\"Data inserted successfully into MySQL database.\")\n",
    "\n",
    "    except pymysql.MySQLError as err:\n",
    "        print(f\"Error: {err}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    all_bus_details = scrape_all_pages()\n",
    "    insert_data_into_mysql(all_bus_details)\n",
    "    df = pd.DataFrame(all_bus_details)\n",
    "    df.to_csv('HSRTC_bus_details.csv', index=False)\n",
    "    print(\"Scraping completed. Data saved to 'HSRTC_bus_details.csv' and MySQL database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ece2908f-58d9-4419-8396-4f9ae127cc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"C:/Users/Lokesh J/Downloads/RedBus_Scrapped_Data/HSRTC_bus_details.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21754c8d-126a-4801-9f04-c21c58df4f0c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Kadamba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24159ba4-2781-4fe0-ac33-d4fcf75deef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/calangute-goa-to-mopa-airport\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/goa-airport-to-goa\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/belagavi-to-goa\n",
      "Data inserted successfully into MySQL database.\n",
      "Scraping completed. Data saved to 'Kadamba_bus_details.csv' and MySQL database.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "import pymysql.cursors\n",
    "\n",
    "URL = \"https://www.redbus.in/online-booking/ktcl/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "def scrape_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(5)\n",
    "        except:\n",
    "            print(f\"No 'View Buses' button found for {url}\")\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)\n",
    "\n",
    "        bus_name_elements = driver.find_elements(By.CSS_SELECTOR, \".travels.lh-24.f-bold.d-color\")\n",
    "        bus_type_elements = driver.find_elements(By.CSS_SELECTOR, \".bus-type.f-12.m-top-16.l-color\")\n",
    "        departing_time_elements = driver.find_elements(By.CSS_SELECTOR, \".dp-time.f-19.d-color.f-bold\")\n",
    "        duration_elements = driver.find_elements(By.CSS_SELECTOR, \".dur.l-color.lh-24\")\n",
    "        reaching_time_elements = driver.find_elements(By.CSS_SELECTOR, \".bp-time.f-19.d-color.disp-Inline\")\n",
    "        star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price_elements = driver.find_elements(By.CSS_SELECTOR, \".fare.d-block\")\n",
    "        seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left')]\")\n",
    "        \n",
    "        bus_details = []\n",
    "\n",
    "        for i in range(len(bus_name_elements)):\n",
    "            try:\n",
    "                seat_availability = seat_availability_elements[i].text if i < len(seat_availability_elements) else 'N/A'\n",
    "                seat_availability = int(seat_availability) if seat_availability.isdigit() else 0\n",
    "\n",
    "                price_text = price_elements[i].text\n",
    "                price_numeric = ''.join(filter(str.isdigit, price_text))\n",
    "\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_numeric,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else 'N/A'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred while scraping bus details: {str(e)}\")\n",
    "        return bus_details\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def scrape_all_pages():\n",
    "    all_bus_details = []\n",
    "    for page in range(1, 5):\n",
    "        try:\n",
    "            driver = initialize_driver()\n",
    "            load_page(driver, URL)\n",
    "            \n",
    "            if page > 1:\n",
    "                pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                time.sleep(5)\n",
    "\n",
    "            all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "            for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                bus_details = scrape_bus_details(driver, link, name)\n",
    "                if bus_details:\n",
    "                    all_bus_details.extend(bus_details)\n",
    "            driver.quit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "\n",
    "    return all_bus_details\n",
    "\n",
    "def insert_data_into_mysql(data):\n",
    "    try:\n",
    "        connection = pymysql.connect(\n",
    "            host='127.0.0.1',\n",
    "            user='root',\n",
    "            password='Root',\n",
    "            database='redbus',\n",
    "            cursorclass=pymysql.cursors.DictCursor\n",
    "        )\n",
    "        \n",
    "        with connection:\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS Kadamba_bus_details (\n",
    "                    Route_Name TEXT,\n",
    "                    Route_Link TEXT,\n",
    "                    Bus_Name TEXT,\n",
    "                    Bus_Type TEXT,\n",
    "                    Departing_Time TIME,\n",
    "                    Duration TEXT,\n",
    "                    Reaching_Time TIME,\n",
    "                    Star_Rating FLOAT,\n",
    "                    Price DECIMAL(10,2),\n",
    "                    Seat_Availability TEXT\n",
    "                )\n",
    "                \"\"\")\n",
    "\n",
    "                for detail in data:\n",
    "                    cursor.execute(\"\"\"\n",
    "                    INSERT INTO Kadamba_bus_details (\n",
    "                        Route_Name, Route_Link, Bus_Name, Bus_Type, Departing_Time, \n",
    "                        Duration, Reaching_Time, Star_Rating, Price, Seat_Availability\n",
    "                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                    \"\"\", (\n",
    "                        detail['Route_Name'], detail['Route_Link'], detail['Bus_Name'], \n",
    "                        detail['Bus_Type'], detail['Departing_Time'], detail['Duration'], \n",
    "                        detail['Reaching_Time'], detail['Star_Rating'], detail['Price'], \n",
    "                        detail['Seat_Availability']\n",
    "                    ))\n",
    "\n",
    "            connection.commit()\n",
    "\n",
    "        print(\"Data inserted successfully into MySQL database.\")\n",
    "\n",
    "    except pymysql.MySQLError as err:\n",
    "        print(f\"Error: {err}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    all_bus_details = scrape_all_pages()\n",
    "    insert_data_into_mysql(all_bus_details)\n",
    "    df = pd.DataFrame(all_bus_details)\n",
    "    df.to_csv('Kadamba_bus_details.csv', index=False)\n",
    "    print(\"Scraping completed. Data saved to 'Kadamba_bus_details.csv' and MySQL database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "199691eb-6699-44c1-be0b-dce283a2a156",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"C:/Users/Lokesh J/Downloads/RedBus_Scrapped_Data/Kadamba_bus_details.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f3f77d-1436-4122-b641-a42a12d6341c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# JKSRTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d9aa8c7e-8a5d-4200-874d-785aac2ced8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/delhi-to-srinagar\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/jammu-to-poonch\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/mendhar-j-k-to-jammu\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/kishtwar-to-jammu\n",
      "Data inserted successfully into MySQL database.\n",
      "Scraping completed. Data saved to 'JKSRTC_bus_details.csv' and MySQL database.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "import pymysql.cursors\n",
    "\n",
    "URL = \"https://www.redbus.in/online-booking/jksrtc\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "def scrape_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(5)\n",
    "        except:\n",
    "            print(f\"No 'View Buses' button found for {url}\")\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)\n",
    "\n",
    "        bus_name_elements = driver.find_elements(By.CSS_SELECTOR, \".travels.lh-24.f-bold.d-color\")\n",
    "        bus_type_elements = driver.find_elements(By.CSS_SELECTOR, \".bus-type.f-12.m-top-16.l-color\")\n",
    "        departing_time_elements = driver.find_elements(By.CSS_SELECTOR, \".dp-time.f-19.d-color.f-bold\")\n",
    "        duration_elements = driver.find_elements(By.CSS_SELECTOR, \".dur.l-color.lh-24\")\n",
    "        reaching_time_elements = driver.find_elements(By.CSS_SELECTOR, \".bp-time.f-19.d-color.disp-Inline\")\n",
    "        star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price_elements = driver.find_elements(By.CSS_SELECTOR, \".fare.d-block\")\n",
    "        seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left')]\")\n",
    "        \n",
    "        bus_details = []\n",
    "\n",
    "        for i in range(len(bus_name_elements)):\n",
    "            try:\n",
    "                seat_availability = seat_availability_elements[i].text if i < len(seat_availability_elements) else 'N/A'\n",
    "                seat_availability = int(seat_availability) if seat_availability.isdigit() else 0\n",
    "\n",
    "                price_text = price_elements[i].text\n",
    "                price_numeric = ''.join(filter(str.isdigit, price_text))\n",
    "\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_numeric,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else 'N/A'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred while scraping bus details: {str(e)}\")\n",
    "        return bus_details\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def scrape_all_pages():\n",
    "    all_bus_details = []\n",
    "    for page in range(1, 2):\n",
    "        try:\n",
    "            driver = initialize_driver()\n",
    "            load_page(driver, URL)\n",
    "            \n",
    "            if page > 1:\n",
    "                pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                time.sleep(5)\n",
    "\n",
    "            all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "            for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                bus_details = scrape_bus_details(driver, link, name)\n",
    "                if bus_details:\n",
    "                    all_bus_details.extend(bus_details)\n",
    "            driver.quit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "\n",
    "    return all_bus_details\n",
    "\n",
    "def insert_data_into_mysql(data):\n",
    "    try:\n",
    "        connection = pymysql.connect(\n",
    "            host='127.0.0.1',\n",
    "            user='root',\n",
    "            password='Root',\n",
    "            database='redbus',\n",
    "            cursorclass=pymysql.cursors.DictCursor\n",
    "        )\n",
    "        \n",
    "        with connection:\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS JKSRTC_bus_details (\n",
    "                    Route_Name TEXT,\n",
    "                    Route_Link TEXT,\n",
    "                    Bus_Name TEXT,\n",
    "                    Bus_Type TEXT,\n",
    "                    Departing_Time TIME,\n",
    "                    Duration TEXT,\n",
    "                    Reaching_Time TIME,\n",
    "                    Star_Rating FLOAT,\n",
    "                    Price DECIMAL(10,2),\n",
    "                    Seat_Availability TEXT\n",
    "                )\n",
    "                \"\"\")\n",
    "\n",
    "                for detail in data:\n",
    "                    cursor.execute(\"\"\"\n",
    "                    INSERT INTO JKSRTC_bus_details (\n",
    "                        Route_Name, Route_Link, Bus_Name, Bus_Type, Departing_Time, \n",
    "                        Duration, Reaching_Time, Star_Rating, Price, Seat_Availability\n",
    "                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                    \"\"\", (\n",
    "                        detail['Route_Name'], detail['Route_Link'], detail['Bus_Name'], \n",
    "                        detail['Bus_Type'], detail['Departing_Time'], detail['Duration'], \n",
    "                        detail['Reaching_Time'], detail['Star_Rating'], detail['Price'], \n",
    "                        detail['Seat_Availability']\n",
    "                    ))\n",
    "\n",
    "            connection.commit()\n",
    "\n",
    "        print(\"Data inserted successfully into MySQL database.\")\n",
    "\n",
    "    except pymysql.MySQLError as err:\n",
    "        print(f\"Error: {err}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    all_bus_details = scrape_all_pages()\n",
    "    insert_data_into_mysql(all_bus_details)\n",
    "    df = pd.DataFrame(all_bus_details)\n",
    "    df.to_csv('JKSRTC_bus_details.csv', index=False)\n",
    "    print(\"Scraping completed. Data saved to 'JKSRTC_bus_details.csv' and MySQL database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1cbb9660-2e9d-4fc9-adaf-4aba561206f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"C:/Users/Lokesh J/Downloads/RedBus_Scrapped_Data/JKSRTC_bus_details.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75013bc-c7d2-4929-bc86-f517f6ad75c8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# KSRTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d00213eb-575a-4a31-90f0-8bdbc998f813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully into MySQL database.\n",
      "Scraping completed. Data saved to 'KSRTC_bus_details.csv' and MySQL database.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "import pymysql.cursors\n",
    "\n",
    "URL = \"https://www.redbus.in/online-booking/ksrtc-kerala/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "def scrape_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(5)\n",
    "        except:\n",
    "            print(f\"No 'View Buses' button found for {url}\")\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)\n",
    "\n",
    "        bus_name_elements = driver.find_elements(By.CSS_SELECTOR, \".travels.lh-24.f-bold.d-color\")\n",
    "        bus_type_elements = driver.find_elements(By.CSS_SELECTOR, \".bus-type.f-12.m-top-16.l-color\")\n",
    "        departing_time_elements = driver.find_elements(By.CSS_SELECTOR, \".dp-time.f-19.d-color.f-bold\")\n",
    "        duration_elements = driver.find_elements(By.CSS_SELECTOR, \".dur.l-color.lh-24\")\n",
    "        reaching_time_elements = driver.find_elements(By.CSS_SELECTOR, \".bp-time.f-19.d-color.disp-Inline\")\n",
    "        star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price_elements = driver.find_elements(By.CSS_SELECTOR, \".fare.d-block\")\n",
    "        seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left')]\")\n",
    "        \n",
    "        bus_details = []\n",
    "\n",
    "        for i in range(len(bus_name_elements)):\n",
    "            try:\n",
    "                seat_availability = seat_availability_elements[i].text if i < len(seat_availability_elements) else 'N/A'\n",
    "                seat_availability = int(seat_availability) if seat_availability.isdigit() else 0\n",
    "\n",
    "                price_text = price_elements[i].text\n",
    "                price_numeric = ''.join(filter(str.isdigit, price_text))\n",
    "\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_numeric,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else 'N/A'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred while scraping bus details: {str(e)}\")\n",
    "        return bus_details\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def scrape_all_pages():\n",
    "    all_bus_details = []\n",
    "    for page in range(1, 3):\n",
    "        try:\n",
    "            driver = initialize_driver()\n",
    "            load_page(driver, URL)\n",
    "            \n",
    "            if page > 1:\n",
    "                pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                time.sleep(5)\n",
    "\n",
    "            all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "            for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                bus_details = scrape_bus_details(driver, link, name)\n",
    "                if bus_details:\n",
    "                    all_bus_details.extend(bus_details)\n",
    "            driver.quit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "\n",
    "    return all_bus_details\n",
    "\n",
    "def insert_data_into_mysql(data):\n",
    "    try:\n",
    "        connection = pymysql.connect(\n",
    "            host='127.0.0.1',\n",
    "            user='root',\n",
    "            password='Root',\n",
    "            database='redbus',\n",
    "            cursorclass=pymysql.cursors.DictCursor\n",
    "        )\n",
    "        \n",
    "        with connection:\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS KSRTC_bus_details (\n",
    "                    Route_Name TEXT,\n",
    "                    Route_Link TEXT,\n",
    "                    Bus_Name TEXT,\n",
    "                    Bus_Type TEXT,\n",
    "                    Departing_Time TIME,\n",
    "                    Duration TEXT,\n",
    "                    Reaching_Time TIME,\n",
    "                    Star_Rating FLOAT,\n",
    "                    Price DECIMAL(10,2),\n",
    "                    Seat_Availability TEXT\n",
    "                )\n",
    "                \"\"\")\n",
    "\n",
    "                for detail in data:\n",
    "                    cursor.execute(\"\"\"\n",
    "                    INSERT INTO KSRTC_bus_details (\n",
    "                        Route_Name, Route_Link, Bus_Name, Bus_Type, Departing_Time, \n",
    "                        Duration, Reaching_Time, Star_Rating, Price, Seat_Availability\n",
    "                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                    \"\"\", (\n",
    "                        detail['Route_Name'], detail['Route_Link'], detail['Bus_Name'], \n",
    "                        detail['Bus_Type'], detail['Departing_Time'], detail['Duration'], \n",
    "                        detail['Reaching_Time'], detail['Star_Rating'], detail['Price'], \n",
    "                        detail['Seat_Availability']\n",
    "                    ))\n",
    "\n",
    "            connection.commit()\n",
    "\n",
    "        print(\"Data inserted successfully into MySQL database.\")\n",
    "\n",
    "    except pymysql.MySQLError as err:\n",
    "        print(f\"Error: {err}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    all_bus_details = scrape_all_pages()\n",
    "    insert_data_into_mysql(all_bus_details)\n",
    "    df = pd.DataFrame(all_bus_details)\n",
    "    df.to_csv('KSRTC_bus_details.csv', index=False)\n",
    "    print(\"Scraping completed. Data saved to 'KSRTC_bus_details.csv' and MySQL database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a9db02d1-0131-4e08-8cc4-149f0a0e38ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"C:/Users/Lokesh J/Downloads/RedBus_Scrapped_Data/KSRTC_bus_details.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3955deec-a5a8-4bd2-a739-b54b2bc809f2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# NBSTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c35c0130-311d-4c13-b4ac-49d2f36f12f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/siliguri-to-darjeeling\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/cooch-behar-west-bengal-to-kolkata\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/siliguri-to-cooch-behar-west-bengal\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/raiganj-to-balurghat\n",
      "Data inserted successfully into MySQL database.\n",
      "Scraping completed. Data saved to 'NBSTC_bus_details.csv' and MySQL database.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "import pymysql.cursors\n",
    "\n",
    "URL = \"https://www.redbus.in/online-booking/north-bengal-state-transport-corporation\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "def scrape_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(5)\n",
    "        except:\n",
    "            print(f\"No 'View Buses' button found for {url}\")\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)\n",
    "\n",
    "        bus_name_elements = driver.find_elements(By.CSS_SELECTOR, \".travels.lh-24.f-bold.d-color\")\n",
    "        bus_type_elements = driver.find_elements(By.CSS_SELECTOR, \".bus-type.f-12.m-top-16.l-color\")\n",
    "        departing_time_elements = driver.find_elements(By.CSS_SELECTOR, \".dp-time.f-19.d-color.f-bold\")\n",
    "        duration_elements = driver.find_elements(By.CSS_SELECTOR, \".dur.l-color.lh-24\")\n",
    "        reaching_time_elements = driver.find_elements(By.CSS_SELECTOR, \".bp-time.f-19.d-color.disp-Inline\")\n",
    "        star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price_elements = driver.find_elements(By.CSS_SELECTOR, \".fare.d-block\")\n",
    "        seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left')]\")\n",
    "        \n",
    "        bus_details = []\n",
    "\n",
    "        for i in range(len(bus_name_elements)):\n",
    "            try:\n",
    "                seat_availability = seat_availability_elements[i].text if i < len(seat_availability_elements) else 'N/A'\n",
    "                seat_availability = int(seat_availability) if seat_availability.isdigit() else 0\n",
    "\n",
    "                price_text = price_elements[i].text\n",
    "                price_numeric = ''.join(filter(str.isdigit, price_text))\n",
    "\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_numeric,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else 'N/A'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred while scraping bus details: {str(e)}\")\n",
    "        return bus_details\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def scrape_all_pages():\n",
    "    all_bus_details = []\n",
    "    for page in range(1, 6):\n",
    "        try:\n",
    "            driver = initialize_driver()\n",
    "            load_page(driver, URL)\n",
    "            \n",
    "            if page > 1:\n",
    "                pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                time.sleep(5)\n",
    "\n",
    "            all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "            for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                bus_details = scrape_bus_details(driver, link, name)\n",
    "                if bus_details:\n",
    "                    all_bus_details.extend(bus_details)\n",
    "            driver.quit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "\n",
    "    return all_bus_details\n",
    "\n",
    "def insert_data_into_mysql(data):\n",
    "    try:\n",
    "        connection = pymysql.connect(\n",
    "            host='127.0.0.1',\n",
    "            user='root',\n",
    "            password='Root',\n",
    "            database='redbus',\n",
    "            cursorclass=pymysql.cursors.DictCursor\n",
    "        )\n",
    "        \n",
    "        with connection:\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS NBSTC_bus_details (\n",
    "                    Route_Name TEXT,\n",
    "                    Route_Link TEXT,\n",
    "                    Bus_Name TEXT,\n",
    "                    Bus_Type TEXT,\n",
    "                    Departing_Time TIME,\n",
    "                    Duration TEXT,\n",
    "                    Reaching_Time TIME,\n",
    "                    Star_Rating FLOAT,\n",
    "                    Price DECIMAL(10,2),\n",
    "                    Seat_Availability TEXT\n",
    "                )\n",
    "                \"\"\")\n",
    "\n",
    "                for detail in data:\n",
    "                    cursor.execute(\"\"\"\n",
    "                    INSERT INTO NBSTC_bus_details (\n",
    "                        Route_Name, Route_Link, Bus_Name, Bus_Type, Departing_Time, \n",
    "                        Duration, Reaching_Time, Star_Rating, Price, Seat_Availability\n",
    "                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                    \"\"\", (\n",
    "                        detail['Route_Name'], detail['Route_Link'], detail['Bus_Name'], \n",
    "                        detail['Bus_Type'], detail['Departing_Time'], detail['Duration'], \n",
    "                        detail['Reaching_Time'], detail['Star_Rating'], detail['Price'], \n",
    "                        detail['Seat_Availability']\n",
    "                    ))\n",
    "\n",
    "            connection.commit()\n",
    "\n",
    "        print(\"Data inserted successfully into MySQL database.\")\n",
    "\n",
    "    except pymysql.MySQLError as err:\n",
    "        print(f\"Error: {err}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    all_bus_details = scrape_all_pages()\n",
    "    insert_data_into_mysql(all_bus_details)\n",
    "    df = pd.DataFrame(all_bus_details)\n",
    "    df.to_csv('NBSTC_bus_details.csv', index=False)\n",
    "    print(\"Scraping completed. Data saved to 'NBSTC_bus_details.csv' and MySQL database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "985e7c33-d1e0-4163-9af9-2fa72fefcfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"C:/Users/Lokesh J/Downloads/RedBus_Scrapped_Data/NBSTC_bus_details.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5349843a-875f-4f16-828c-833eecef6b20",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Punjab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ec574bbd-47e9-4bee-9fbc-e19acafdc7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully into MySQL database.\n",
      "Scraping completed. Data saved to 'PEPSU_bus_details.csv' and MySQL database.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "import pymysql.cursors\n",
    "\n",
    "URL = \"https://www.redbus.in/online-booking/pepsu/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "def scrape_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(5)\n",
    "        except:\n",
    "            print(f\"No 'View Buses' button found for {url}\")\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)\n",
    "\n",
    "        bus_name_elements = driver.find_elements(By.CSS_SELECTOR, \".travels.lh-24.f-bold.d-color\")\n",
    "        bus_type_elements = driver.find_elements(By.CSS_SELECTOR, \".bus-type.f-12.m-top-16.l-color\")\n",
    "        departing_time_elements = driver.find_elements(By.CSS_SELECTOR, \".dp-time.f-19.d-color.f-bold\")\n",
    "        duration_elements = driver.find_elements(By.CSS_SELECTOR, \".dur.l-color.lh-24\")\n",
    "        reaching_time_elements = driver.find_elements(By.CSS_SELECTOR, \".bp-time.f-19.d-color.disp-Inline\")\n",
    "        star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price_elements = driver.find_elements(By.CSS_SELECTOR, \".fare.d-block\")\n",
    "        seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left')]\")\n",
    "        \n",
    "        bus_details = []\n",
    "\n",
    "        for i in range(len(bus_name_elements)):\n",
    "            try:\n",
    "                seat_availability = seat_availability_elements[i].text if i < len(seat_availability_elements) else 'N/A'\n",
    "                seat_availability = int(seat_availability) if seat_availability.isdigit() else 0\n",
    "\n",
    "                price_text = price_elements[i].text\n",
    "                price_numeric = ''.join(filter(str.isdigit, price_text))\n",
    "\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_numeric,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else 'N/A'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred while scraping bus details: {str(e)}\")\n",
    "        return bus_details\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def scrape_all_pages():\n",
    "    all_bus_details = []\n",
    "    for page in range(1, 3):\n",
    "        try:\n",
    "            driver = initialize_driver()\n",
    "            load_page(driver, URL)\n",
    "            \n",
    "            if page > 1:\n",
    "                pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                time.sleep(5)\n",
    "\n",
    "            all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "            for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                bus_details = scrape_bus_details(driver, link, name)\n",
    "                if bus_details:\n",
    "                    all_bus_details.extend(bus_details)\n",
    "            driver.quit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "\n",
    "    return all_bus_details\n",
    "\n",
    "def insert_data_into_mysql(data):\n",
    "    try:\n",
    "        connection = pymysql.connect(\n",
    "            host='127.0.0.1',\n",
    "            user='root',\n",
    "            password='Root',\n",
    "            database='redbus',\n",
    "            cursorclass=pymysql.cursors.DictCursor\n",
    "        )\n",
    "        \n",
    "        with connection:\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS PEPSU_bus_details (\n",
    "                    Route_Name TEXT,\n",
    "                    Route_Link TEXT,\n",
    "                    Bus_Name TEXT,\n",
    "                    Bus_Type TEXT,\n",
    "                    Departing_Time TIME,\n",
    "                    Duration TEXT,\n",
    "                    Reaching_Time TIME,\n",
    "                    Star_Rating FLOAT,\n",
    "                    Price DECIMAL(10,2),\n",
    "                    Seat_Availability TEXT\n",
    "                )\n",
    "                \"\"\")\n",
    "\n",
    "                for detail in data:\n",
    "                    cursor.execute(\"\"\"\n",
    "                    INSERT INTO PEPSU_bus_details (\n",
    "                        Route_Name, Route_Link, Bus_Name, Bus_Type, Departing_Time, \n",
    "                        Duration, Reaching_Time, Star_Rating, Price, Seat_Availability\n",
    "                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                    \"\"\", (\n",
    "                        detail['Route_Name'], detail['Route_Link'], detail['Bus_Name'], \n",
    "                        detail['Bus_Type'], detail['Departing_Time'], detail['Duration'], \n",
    "                        detail['Reaching_Time'], detail['Star_Rating'], detail['Price'], \n",
    "                        detail['Seat_Availability']\n",
    "                    ))\n",
    "\n",
    "            connection.commit()\n",
    "\n",
    "        print(\"Data inserted successfully into MySQL database.\")\n",
    "\n",
    "    except pymysql.MySQLError as err:\n",
    "        print(f\"Error: {err}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    all_bus_details = scrape_all_pages()\n",
    "    insert_data_into_mysql(all_bus_details)\n",
    "    df = pd.DataFrame(all_bus_details)\n",
    "    df.to_csv('PEPSU_bus_details.csv', index=False)\n",
    "    print(\"Scraping completed. Data saved to 'PEPSU_bus_details.csv' and MySQL database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d38172e5-8354-4bc9-8a77-872be9392d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"C:/Users/Lokesh J/Downloads/RedBus_Scrapped_Data/PEPSU_bus_details.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcc1e73-b97e-4d8a-96ad-291737ca8e46",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# RSRTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d679fcab-3921-4f15-986a-ec8f8d5220d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully into MySQL database.\n",
      "Scraping completed. Data saved to 'RSRTC_bus_details.csv' and MySQL database.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "import pymysql.cursors\n",
    "\n",
    "URL = \"https://www.redbus.in/online-booking/rsrtc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "def scrape_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(5)\n",
    "        except:\n",
    "            print(f\"No 'View Buses' button found for {url}\")\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)\n",
    "\n",
    "        bus_name_elements = driver.find_elements(By.CSS_SELECTOR, \".travels.lh-24.f-bold.d-color\")\n",
    "        bus_type_elements = driver.find_elements(By.CSS_SELECTOR, \".bus-type.f-12.m-top-16.l-color\")\n",
    "        departing_time_elements = driver.find_elements(By.CSS_SELECTOR, \".dp-time.f-19.d-color.f-bold\")\n",
    "        duration_elements = driver.find_elements(By.CSS_SELECTOR, \".dur.l-color.lh-24\")\n",
    "        reaching_time_elements = driver.find_elements(By.CSS_SELECTOR, \".bp-time.f-19.d-color.disp-Inline\")\n",
    "        star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price_elements = driver.find_elements(By.CSS_SELECTOR, \".fare.d-block\")\n",
    "        seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left')]\")\n",
    "        \n",
    "        bus_details = []\n",
    "\n",
    "        for i in range(len(bus_name_elements)):\n",
    "            try:\n",
    "                seat_availability = seat_availability_elements[i].text if i < len(seat_availability_elements) else 'N/A'\n",
    "                seat_availability = int(seat_availability) if seat_availability.isdigit() else 0\n",
    "\n",
    "                price_text = price_elements[i].text\n",
    "                price_numeric = ''.join(filter(str.isdigit, price_text))\n",
    "\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_numeric,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else 'N/A'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred while scraping bus details: {str(e)}\")\n",
    "        return bus_details\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def scrape_all_pages():\n",
    "    all_bus_details = []\n",
    "    for page in range(1, 3):\n",
    "        try:\n",
    "            driver = initialize_driver()\n",
    "            load_page(driver, URL)\n",
    "            \n",
    "            if page > 1:\n",
    "                pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                time.sleep(5)\n",
    "\n",
    "            all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "            for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                bus_details = scrape_bus_details(driver, link, name)\n",
    "                if bus_details:\n",
    "                    all_bus_details.extend(bus_details)\n",
    "            driver.quit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "\n",
    "    return all_bus_details\n",
    "\n",
    "def insert_data_into_mysql(data):\n",
    "    try:\n",
    "        connection = pymysql.connect(\n",
    "            host='127.0.0.1',\n",
    "            user='root',\n",
    "            password='Root',\n",
    "            database='redbus',\n",
    "            cursorclass=pymysql.cursors.DictCursor\n",
    "        )\n",
    "        \n",
    "        with connection:\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS RSRTC_bus_details (\n",
    "                    Route_Name TEXT,\n",
    "                    Route_Link TEXT,\n",
    "                    Bus_Name TEXT,\n",
    "                    Bus_Type TEXT,\n",
    "                    Departing_Time TIME,\n",
    "                    Duration TEXT,\n",
    "                    Reaching_Time TIME,\n",
    "                    Star_Rating FLOAT,\n",
    "                    Price DECIMAL(10,2),\n",
    "                    Seat_Availability TEXT\n",
    "                )\n",
    "                \"\"\")\n",
    "\n",
    "                for detail in data:\n",
    "                    cursor.execute(\"\"\"\n",
    "                    INSERT INTO RSRTC_bus_details (\n",
    "                        Route_Name, Route_Link, Bus_Name, Bus_Type, Departing_Time, \n",
    "                        Duration, Reaching_Time, Star_Rating, Price, Seat_Availability\n",
    "                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                    \"\"\", (\n",
    "                        detail['Route_Name'], detail['Route_Link'], detail['Bus_Name'], \n",
    "                        detail['Bus_Type'], detail['Departing_Time'], detail['Duration'], \n",
    "                        detail['Reaching_Time'], detail['Star_Rating'], detail['Price'], \n",
    "                        detail['Seat_Availability']\n",
    "                    ))\n",
    "\n",
    "            connection.commit()\n",
    "\n",
    "        print(\"Data inserted successfully into MySQL database.\")\n",
    "\n",
    "    except pymysql.MySQLError as err:\n",
    "        print(f\"Error: {err}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    all_bus_details = scrape_all_pages()\n",
    "    insert_data_into_mysql(all_bus_details)\n",
    "    df = pd.DataFrame(all_bus_details)\n",
    "    df.to_csv('RSRTC_bus_details.csv', index=False)\n",
    "    print(\"Scraping completed. Data saved to 'RSRTC_bus_details.csv' and MySQL database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "069456ae-705e-4cfa-8d37-89a128d3e226",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"C:/Users/Lokesh J/Downloads/RedBus_Scrapped_Data/RSRTC_bus_details.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2ae4e2-b568-478e-a73e-14fe10bae09d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# SBSTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2ac1b605-d563-4599-964e-f70a72b52930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/jhargram-to-kolkata\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/barasat-west-bengal-to-midnapore\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/kirnahar-west-bengal-to-kolkata\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/berhampore-to-durgapur\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/purulia-to-durgapur\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/durgapur-to-berhampore\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/durgapur-to-barasat-west-bengal\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/barasat-west-bengal-to-digha\n",
      "Data inserted successfully into MySQL database.\n",
      "Scraping completed. Data saved to 'SBSTC_bus_details.csv' and MySQL database.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "import pymysql.cursors\n",
    "\n",
    "URL = \"https://www.redbus.in/online-booking/south-bengal-state-transport-corporation-sbstc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "def scrape_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(5)\n",
    "        except:\n",
    "            print(f\"No 'View Buses' button found for {url}\")\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)\n",
    "\n",
    "        bus_name_elements = driver.find_elements(By.CSS_SELECTOR, \".travels.lh-24.f-bold.d-color\")\n",
    "        bus_type_elements = driver.find_elements(By.CSS_SELECTOR, \".bus-type.f-12.m-top-16.l-color\")\n",
    "        departing_time_elements = driver.find_elements(By.CSS_SELECTOR, \".dp-time.f-19.d-color.f-bold\")\n",
    "        duration_elements = driver.find_elements(By.CSS_SELECTOR, \".dur.l-color.lh-24\")\n",
    "        reaching_time_elements = driver.find_elements(By.CSS_SELECTOR, \".bp-time.f-19.d-color.disp-Inline\")\n",
    "        star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price_elements = driver.find_elements(By.CSS_SELECTOR, \".fare.d-block\")\n",
    "        seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left')]\")\n",
    "        \n",
    "        bus_details = []\n",
    "\n",
    "        for i in range(len(bus_name_elements)):\n",
    "            try:\n",
    "                seat_availability = seat_availability_elements[i].text if i < len(seat_availability_elements) else 'N/A'\n",
    "                seat_availability = int(seat_availability) if seat_availability.isdigit() else 0\n",
    "\n",
    "                price_text = price_elements[i].text\n",
    "                price_numeric = ''.join(filter(str.isdigit, price_text))\n",
    "\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_numeric,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else 'N/A'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred while scraping bus details: {str(e)}\")\n",
    "        return bus_details\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def scrape_all_pages():\n",
    "    all_bus_details = []\n",
    "    for page in range(1, 6):\n",
    "        try:\n",
    "            driver = initialize_driver()\n",
    "            load_page(driver, URL)\n",
    "            \n",
    "            if page > 1:\n",
    "                pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                time.sleep(5)\n",
    "\n",
    "            all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "            for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                bus_details = scrape_bus_details(driver, link, name)\n",
    "                if bus_details:\n",
    "                    all_bus_details.extend(bus_details)\n",
    "            driver.quit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "\n",
    "    return all_bus_details\n",
    "\n",
    "def insert_data_into_mysql(data):\n",
    "    try:\n",
    "        connection = pymysql.connect(\n",
    "            host='127.0.0.1',\n",
    "            user='root',\n",
    "            password='Root',\n",
    "            database='redbus',\n",
    "            cursorclass=pymysql.cursors.DictCursor\n",
    "        )\n",
    "        \n",
    "        with connection:\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS SBSTC_bus_details (\n",
    "                    Route_Name TEXT,\n",
    "                    Route_Link TEXT,\n",
    "                    Bus_Name TEXT,\n",
    "                    Bus_Type TEXT,\n",
    "                    Departing_Time TIME,\n",
    "                    Duration TEXT,\n",
    "                    Reaching_Time TIME,\n",
    "                    Star_Rating FLOAT,\n",
    "                    Price DECIMAL(10,2),\n",
    "                    Seat_Availability TEXT\n",
    "                )\n",
    "                \"\"\")\n",
    "\n",
    "                for detail in data:\n",
    "                    cursor.execute(\"\"\"\n",
    "                    INSERT INTO SBSTC_bus_details (\n",
    "                        Route_Name, Route_Link, Bus_Name, Bus_Type, Departing_Time, \n",
    "                        Duration, Reaching_Time, Star_Rating, Price, Seat_Availability\n",
    "                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                    \"\"\", (\n",
    "                        detail['Route_Name'], detail['Route_Link'], detail['Bus_Name'], \n",
    "                        detail['Bus_Type'], detail['Departing_Time'], detail['Duration'], \n",
    "                        detail['Reaching_Time'], detail['Star_Rating'], detail['Price'], \n",
    "                        detail['Seat_Availability']\n",
    "                    ))\n",
    "\n",
    "            connection.commit()\n",
    "\n",
    "        print(\"Data inserted successfully into MySQL database.\")\n",
    "\n",
    "    except pymysql.MySQLError as err:\n",
    "        print(f\"Error: {err}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    all_bus_details = scrape_all_pages()\n",
    "    insert_data_into_mysql(all_bus_details)\n",
    "    df = pd.DataFrame(all_bus_details)\n",
    "    df.to_csv('SBSTC_bus_details.csv', index=False)\n",
    "    print(\"Scraping completed. Data saved to 'SBSTC_bus_details.csv' and MySQL database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "77619aaf-e4ee-489f-adbe-faf10bb6186f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"C:/Users/Lokesh J/Downloads/RedBus_Scrapped_Data/SBSTC_bus_details.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9507bed8-492b-49b7-b113-41aa3a932656",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# TSRTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "03e1528a-c3ea-46ed-901c-ecebe6581a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully into MySQL database.\n",
      "Scraping completed. Data saved to 'TSRTC_bus_details.csv' and MySQL database.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "import pymysql.cursors\n",
    "\n",
    "URL = \"https://www.redbus.in/online-booking/tsrtc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "def scrape_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(5)\n",
    "        except:\n",
    "            print(f\"No 'View Buses' button found for {url}\")\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)\n",
    "\n",
    "        bus_name_elements = driver.find_elements(By.CSS_SELECTOR, \".travels.lh-24.f-bold.d-color\")\n",
    "        bus_type_elements = driver.find_elements(By.CSS_SELECTOR, \".bus-type.f-12.m-top-16.l-color\")\n",
    "        departing_time_elements = driver.find_elements(By.CSS_SELECTOR, \".dp-time.f-19.d-color.f-bold\")\n",
    "        duration_elements = driver.find_elements(By.CSS_SELECTOR, \".dur.l-color.lh-24\")\n",
    "        reaching_time_elements = driver.find_elements(By.CSS_SELECTOR, \".bp-time.f-19.d-color.disp-Inline\")\n",
    "        star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price_elements = driver.find_elements(By.CSS_SELECTOR, \".fare.d-block\")\n",
    "        seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left')]\")\n",
    "        \n",
    "        bus_details = []\n",
    "\n",
    "        for i in range(len(bus_name_elements)):\n",
    "            try:\n",
    "                seat_availability = seat_availability_elements[i].text if i < len(seat_availability_elements) else 'N/A'\n",
    "                seat_availability = int(seat_availability) if seat_availability.isdigit() else 0\n",
    "\n",
    "                price_text = price_elements[i].text\n",
    "                price_numeric = ''.join(filter(str.isdigit, price_text))\n",
    "\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_numeric,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else 'N/A'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred while scraping bus details: {str(e)}\")\n",
    "        return bus_details\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def scrape_all_pages():\n",
    "    all_bus_details = []\n",
    "    for page in range(1, 4):\n",
    "        try:\n",
    "            driver = initialize_driver()\n",
    "            load_page(driver, URL)\n",
    "            \n",
    "            if page > 1:\n",
    "                pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                time.sleep(5)\n",
    "\n",
    "            all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "            for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                bus_details = scrape_bus_details(driver, link, name)\n",
    "                if bus_details:\n",
    "                    all_bus_details.extend(bus_details)\n",
    "            driver.quit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "\n",
    "    return all_bus_details\n",
    "\n",
    "def insert_data_into_mysql(data):\n",
    "    try:\n",
    "        connection = pymysql.connect(\n",
    "            host='127.0.0.1',\n",
    "            user='root',\n",
    "            password='Root',\n",
    "            database='redbus',\n",
    "            cursorclass=pymysql.cursors.DictCursor\n",
    "        )\n",
    "        \n",
    "        with connection:\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS TSRTC_bus_details (\n",
    "                    Route_Name TEXT,\n",
    "                    Route_Link TEXT,\n",
    "                    Bus_Name TEXT,\n",
    "                    Bus_Type TEXT,\n",
    "                    Departing_Time TIME,\n",
    "                    Duration TEXT,\n",
    "                    Reaching_Time TIME,\n",
    "                    Star_Rating FLOAT,\n",
    "                    Price DECIMAL(10,2),\n",
    "                    Seat_Availability TEXT\n",
    "                )\n",
    "                \"\"\")\n",
    "\n",
    "                for detail in data:\n",
    "                    cursor.execute(\"\"\"\n",
    "                    INSERT INTO TSRTC_bus_details (\n",
    "                        Route_Name, Route_Link, Bus_Name, Bus_Type, Departing_Time, \n",
    "                        Duration, Reaching_Time, Star_Rating, Price, Seat_Availability\n",
    "                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                    \"\"\", (\n",
    "                        detail['Route_Name'], detail['Route_Link'], detail['Bus_Name'], \n",
    "                        detail['Bus_Type'], detail['Departing_Time'], detail['Duration'], \n",
    "                        detail['Reaching_Time'], detail['Star_Rating'], detail['Price'], \n",
    "                        detail['Seat_Availability']\n",
    "                    ))\n",
    "\n",
    "            connection.commit()\n",
    "\n",
    "        print(\"Data inserted successfully into MySQL database.\")\n",
    "\n",
    "    except pymysql.MySQLError as err:\n",
    "        print(f\"Error: {err}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    all_bus_details = scrape_all_pages()\n",
    "    insert_data_into_mysql(all_bus_details)\n",
    "    df = pd.DataFrame(all_bus_details)\n",
    "    df.to_csv('TSRTC_bus_details.csv', index=False)\n",
    "    print(\"Scraping completed. Data saved to 'TSRTC_bus_details.csv' and MySQL database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4bb8d956-b661-4943-b056-463040afdc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"C:/Users/Lokesh J/Downloads/RedBus_Scrapped_Data/TSRTC_bus_details.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536a962b-4771-48c0-ab25-4f8fa644377d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# UPSRTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2e4a4b34-7aa5-4b03-bdd7-b7bf497693d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted successfully into MySQL database.\n",
      "Scraping completed. Data saved to 'UPSRTC_bus_details.csv' and MySQL database.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "import pymysql.cursors\n",
    "\n",
    "URL = \"https://www.redbus.in/online-booking/uttar-pradesh-state-road-transport-corporation-upsrtc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "def scrape_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(5)\n",
    "        except:\n",
    "            print(f\"No 'View Buses' button found for {url}\")\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)\n",
    "\n",
    "        bus_name_elements = driver.find_elements(By.CSS_SELECTOR, \".travels.lh-24.f-bold.d-color\")\n",
    "        bus_type_elements = driver.find_elements(By.CSS_SELECTOR, \".bus-type.f-12.m-top-16.l-color\")\n",
    "        departing_time_elements = driver.find_elements(By.CSS_SELECTOR, \".dp-time.f-19.d-color.f-bold\")\n",
    "        duration_elements = driver.find_elements(By.CSS_SELECTOR, \".dur.l-color.lh-24\")\n",
    "        reaching_time_elements = driver.find_elements(By.CSS_SELECTOR, \".bp-time.f-19.d-color.disp-Inline\")\n",
    "        star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price_elements = driver.find_elements(By.CSS_SELECTOR, \".fare.d-block\")\n",
    "        seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left')]\")\n",
    "        \n",
    "        bus_details = []\n",
    "\n",
    "        for i in range(len(bus_name_elements)):\n",
    "            try:\n",
    "                seat_availability = seat_availability_elements[i].text if i < len(seat_availability_elements) else 'N/A'\n",
    "                seat_availability = int(seat_availability) if seat_availability.isdigit() else 0\n",
    "\n",
    "                price_text = price_elements[i].text\n",
    "                price_numeric = ''.join(filter(str.isdigit, price_text))\n",
    "\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_numeric,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else 'N/A'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred while scraping bus details: {str(e)}\")\n",
    "        return bus_details\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def scrape_all_pages():\n",
    "    all_bus_details = []\n",
    "    for page in range(1, 4):\n",
    "        try:\n",
    "            driver = initialize_driver()\n",
    "            load_page(driver, URL)\n",
    "            \n",
    "            if page > 1:\n",
    "                pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                time.sleep(5)\n",
    "\n",
    "            all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "            for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                bus_details = scrape_bus_details(driver, link, name)\n",
    "                if bus_details:\n",
    "                    all_bus_details.extend(bus_details)\n",
    "            driver.quit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "\n",
    "    return all_bus_details\n",
    "\n",
    "def insert_data_into_mysql(data):\n",
    "    try:\n",
    "        connection = pymysql.connect(\n",
    "            host='127.0.0.1',\n",
    "            user='root',\n",
    "            password='Root',\n",
    "            database='redbus',\n",
    "            cursorclass=pymysql.cursors.DictCursor\n",
    "        )\n",
    "        \n",
    "        with connection:\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS UPSRTC_bus_details (\n",
    "                    Route_Name TEXT,\n",
    "                    Route_Link TEXT,\n",
    "                    Bus_Name TEXT,\n",
    "                    Bus_Type TEXT,\n",
    "                    Departing_Time TIME,\n",
    "                    Duration TEXT,\n",
    "                    Reaching_Time TIME,\n",
    "                    Star_Rating FLOAT,\n",
    "                    Price DECIMAL(10,2),\n",
    "                    Seat_Availability TEXT\n",
    "                )\n",
    "                \"\"\")\n",
    "\n",
    "                for detail in data:\n",
    "                    cursor.execute(\"\"\"\n",
    "                    INSERT INTO UPSRTC_bus_details (\n",
    "                        Route_Name, Route_Link, Bus_Name, Bus_Type, Departing_Time, \n",
    "                        Duration, Reaching_Time, Star_Rating, Price, Seat_Availability\n",
    "                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                    \"\"\", (\n",
    "                        detail['Route_Name'], detail['Route_Link'], detail['Bus_Name'], \n",
    "                        detail['Bus_Type'], detail['Departing_Time'], detail['Duration'], \n",
    "                        detail['Reaching_Time'], detail['Star_Rating'], detail['Price'], \n",
    "                        detail['Seat_Availability']\n",
    "                    ))\n",
    "\n",
    "            connection.commit()\n",
    "\n",
    "        print(\"Data inserted successfully into MySQL database.\")\n",
    "\n",
    "    except pymysql.MySQLError as err:\n",
    "        print(f\"Error: {err}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    all_bus_details = scrape_all_pages()\n",
    "    insert_data_into_mysql(all_bus_details)\n",
    "    df = pd.DataFrame(all_bus_details)\n",
    "    df.to_csv('UPSRTC_bus_details.csv', index=False)\n",
    "    print(\"Scraping completed. Data saved to 'UPSRTC_bus_details.csv' and MySQL database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7b545cf8-9438-459c-9cf3-03aa8f9c8be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"C:/Users/Lokesh J/Downloads/RedBus_Scrapped_Data/UPSRTC_bus_details.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2305d966-7ac7-440b-a0f3-534b81f79efd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# WBTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1d893f15-c257-40f8-a7aa-85f9fc0a510b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/barasat-west-bengal-to-digha\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/barasat-west-bengal-to-midnapore\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/midnapore-to-kolkata\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/barasat-west-bengal-to-kolaghat\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/barasat-west-bengal-to-contai-kanthi\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/habra-to-digha\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/barasat-west-bengal-to-nandakumar\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/digha-to-habra\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/midnapore-to-barasat-west-bengal\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/kolkata-to-bolpur-west-bengal\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/barasat-west-bengal-to-durgapur\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/barasat-west-bengal-to-heria\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/barasat-west-bengal-to-haldia\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/barasat-west-bengal-to-debra\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/barasat-west-bengal-to-burdwan\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/kolkata-to-bakkhali\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/habra-to-midnapore\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/durgapur-to-barasat-west-bengal\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/barasat-west-bengal-to-asansol\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/jayrambati-west-bengal-to-barasat-west-bengal\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/habra-to-durgapur\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/habra-to-nandakumar\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/habra-to-kolaghat\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/kolkata-to-mayapur-iskcon\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/habra-to-heria\n",
      "No 'View Buses' button found for https://www.redbus.in/bus-tickets/midnapore-to-kolkata-airport\n",
      "Data inserted successfully into MySQL database.\n",
      "Scraping completed. Data saved to 'WBTC_bus_details.csv' and MySQL database.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "import pymysql.cursors\n",
    "\n",
    "URL = \"https://www.redbus.in/online-booking/wbtc-ctc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "def scrape_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(5)\n",
    "        except:\n",
    "            print(f\"No 'View Buses' button found for {url}\")\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)\n",
    "\n",
    "        bus_name_elements = driver.find_elements(By.CSS_SELECTOR, \".travels.lh-24.f-bold.d-color\")\n",
    "        bus_type_elements = driver.find_elements(By.CSS_SELECTOR, \".bus-type.f-12.m-top-16.l-color\")\n",
    "        departing_time_elements = driver.find_elements(By.CSS_SELECTOR, \".dp-time.f-19.d-color.f-bold\")\n",
    "        duration_elements = driver.find_elements(By.CSS_SELECTOR, \".dur.l-color.lh-24\")\n",
    "        reaching_time_elements = driver.find_elements(By.CSS_SELECTOR, \".bp-time.f-19.d-color.disp-Inline\")\n",
    "        star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "        price_elements = driver.find_elements(By.CSS_SELECTOR, \".fare.d-block\")\n",
    "        seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left')]\")\n",
    "        \n",
    "        bus_details = []\n",
    "\n",
    "        for i in range(len(bus_name_elements)):\n",
    "            try:\n",
    "                seat_availability = seat_availability_elements[i].text if i < len(seat_availability_elements) else 'N/A'\n",
    "                seat_availability = int(seat_availability) if seat_availability.isdigit() else 0\n",
    "\n",
    "                price_text = price_elements[i].text\n",
    "                price_numeric = ''.join(filter(str.isdigit, price_text))\n",
    "\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_numeric,\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else 'N/A'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred while scraping bus details: {str(e)}\")\n",
    "        return bus_details\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def scrape_all_pages():\n",
    "    all_bus_details = []\n",
    "    for page in range(1, 5):\n",
    "        try:\n",
    "            driver = initialize_driver()\n",
    "            load_page(driver, URL)\n",
    "            \n",
    "            if page > 1:\n",
    "                pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                time.sleep(5)\n",
    "\n",
    "            all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "            for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                bus_details = scrape_bus_details(driver, link, name)\n",
    "                if bus_details:\n",
    "                    all_bus_details.extend(bus_details)\n",
    "            driver.quit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "\n",
    "    return all_bus_details\n",
    "\n",
    "def insert_data_into_mysql(data):\n",
    "    try:\n",
    "        connection = pymysql.connect(\n",
    "            host='127.0.0.1',\n",
    "            user='root',\n",
    "            password='Root',\n",
    "            database='redbus',\n",
    "            cursorclass=pymysql.cursors.DictCursor\n",
    "        )\n",
    "        \n",
    "        with connection:\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS WBTC_bus_details (\n",
    "                    Route_Name TEXT,\n",
    "                    Route_Link TEXT,\n",
    "                    Bus_Name TEXT,\n",
    "                    Bus_Type TEXT,\n",
    "                    Departing_Time TIME,\n",
    "                    Duration TEXT,\n",
    "                    Reaching_Time TIME,\n",
    "                    Star_Rating FLOAT,\n",
    "                    Price DECIMAL(10,2),\n",
    "                    Seat_Availability TEXT\n",
    "                )\n",
    "                \"\"\")\n",
    "\n",
    "                for detail in data:\n",
    "                    cursor.execute(\"\"\"\n",
    "                    INSERT INTO WBTC_bus_details (\n",
    "                        Route_Name, Route_Link, Bus_Name, Bus_Type, Departing_Time, \n",
    "                        Duration, Reaching_Time, Star_Rating, Price, Seat_Availability\n",
    "                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                    \"\"\", (\n",
    "                        detail['Route_Name'], detail['Route_Link'], detail['Bus_Name'], \n",
    "                        detail['Bus_Type'], detail['Departing_Time'], detail['Duration'], \n",
    "                        detail['Reaching_Time'], detail['Star_Rating'], detail['Price'], \n",
    "                        detail['Seat_Availability']\n",
    "                    ))\n",
    "\n",
    "            connection.commit()\n",
    "\n",
    "        print(\"Data inserted successfully into MySQL database.\")\n",
    "\n",
    "    except pymysql.MySQLError as err:\n",
    "        print(f\"Error: {err}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    all_bus_details = scrape_all_pages()\n",
    "    insert_data_into_mysql(all_bus_details)\n",
    "    df = pd.DataFrame(all_bus_details)\n",
    "    df.to_csv('WBTC_bus_details.csv', index=False)\n",
    "    print(\"Scraping completed. Data saved to 'WBTC_bus_details.csv' and MySQL database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b3810a49-b5d4-4049-a7ed-372c1af11409",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"C:/Users/Lokesh J/Downloads/RedBus_Scrapped_Data/WBTC_bus_details.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
